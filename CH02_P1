# -*- coding: utf-8 -*-
"""
Created on Mon Jan 18 19:10:04 2016

@author: erick
"""
import json
path = 'C:/Users/erick/Desktop/SCRAP/usagov_bitly_data2012-03-16-1331923249.txt'
records = [json.loads(line) for line in open(path)]

print(records[0]['tz'])

#create list of time zones (via loop)
time_zones = [rec['tz'] for rec in records if 'tz' in rec]

#create dictionary function (histogram)
def get_counts(sequence):
    counts = {}
    for x in sequence:
        if x in counts:
            counts[x] += 1
        else:
            counts[x] = 1
    return counts

counts = get_counts(time_zones)

#top 10 time zones erick
lst=[]
top=[]
for key,value in counts.items():
    lst=[value,key]
    top.append(lst)
    lst=[]
top.sort(reverse=True)
print top[0:10]

#top 10 time zones PDA
from collections import Counter
counts = Counter(time_zones)
print counts.most_common(10) 

#CREATE DATAFRAME FROM DICTIONARY
from pandas import DataFrame, Series
import pandas as pd
frame = DataFrame(records)
frame

#count values in dataframe
tz_counts = frame['tz'].value_counts()

#remove missing values and count values
clean_tz = frame['tz'].fillna('Missing')#sub NAs
clean_tz[clean_tz == ''] = 'Unknown'#sub blanks
tz_counts = clean_tz.value_counts()

#plot
tz_counts[:10].plot(kind='barh', rot=0) 

#parse, split and enlist first item in list "results"
results = Series([x.split()[0] for x in frame.a.dropna()])
#count values
results.value_counts()[:8] 

#subset dataframe from "a" data column
cframe = frame[frame.a.notnull()] 

#compute a value whether each row is Windows or not
import numpy as np
operating_system = np.where(cframe['a'].str.contains('Windows'),'Windows', 'Not Windows')

#group the data by its time zone column and list of operating systems
by_tz_os = cframe.groupby(['tz', operating_system])

#The group counts, analogous to the value_counts function above, can be computed using size. 
#This result is then reshaped into a table with unstac
agg_counts = by_tz_os.size().unstack().fillna(0)

#Finally, letâ€™s select the top overall time zones. 
#I construct an indirect index array from the row counts in agg_counts: 
indexer = agg_counts.sum(1).argsort()

#use 'take' to select the rows in that order, then slice off the last 10 rows: 
count_subset = agg_counts.take(indexer)[-10:]

#plot
count_subset.plot(kind='barh', stacked=True) 
normed_subset = count_subset.div(count_subset.sum(1), axis=0)
normed_subset.plot(kind='barh', stacked=True)



